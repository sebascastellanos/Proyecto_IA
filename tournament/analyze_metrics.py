#!/usr/bin/env python3
"""
üìä An√°lisis de M√©tricas de Entrenamiento Q-Learning
==================================================
Script para analizar y visualizar las m√©tricas de entrenamiento
del agente Q-Learning.
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os
import sys

# Configurar estilo de gr√°ficos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class MetricsAnalyzer:
    """Analizador de m√©tricas de entrenamiento"""
    
    def __init__(self, metrics_file='metrics/training_metrics_final.json'):
        self.metrics_file = metrics_file
        self.metrics = None
        self.load_metrics()
    
    def load_metrics(self):
        """Carga las m√©tricas desde el archivo JSON"""
        try:
            with open(self.metrics_file, 'r') as f:
                self.metrics = json.load(f)
            print(f"‚úÖ M√©tricas cargadas desde {self.metrics_file}")
        except FileNotFoundError:
            print(f"‚ùå No se encontr√≥ el archivo {self.metrics_file}")
            self.metrics = None
        except Exception as e:
            print(f"‚ùå Error cargando m√©tricas: {e}")
            self.metrics = None
    
    def print_summary(self):
        """Imprime un resumen de las m√©tricas"""
        if not self.metrics:
            print("‚ùå No hay m√©tricas disponibles")
            return
        
        print("\\nüéØ RESUMEN DE ENTRENAMIENTO")
        print("=" * 50)
        print(f"üìä Juegos totales: {self.metrics.get('games_played', 0)}")
        print(f"üèÜ Victorias: {self.metrics.get('wins', 0)}")
        print(f"üíî Derrotas: {self.metrics.get('losses', 0)}")
        print(f"ü§ù Empates: {self.metrics.get('draws', 0)}")
        print(f"üìà Tasa de victoria: {self.metrics.get('win_rate', 0):.1%}")
        print(f"‚è±Ô∏è  Duraci√≥n promedio: {self.metrics.get('avg_game_length', 0):.1f} movimientos")
        print(f"üß† Tama√±o tabla Q: {self.metrics.get('q_table_size', 0)} estados")
        print(f"üé≤ Epsilon final: {self.metrics.get('current_epsilon', 0):.3f}")
        print(f"‚ö° Tasa de aprendizaje: {self.metrics.get('learning_rate', 0):.3f}")
        print(f"üí∞ Factor de descuento: {self.metrics.get('discount_factor', 0):.3f}")
        
        if self.metrics.get('training_duration'):
            duration = self.metrics['training_duration']
            print(f"‚è∞ Tiempo de entrenamiento: {duration:.1f}s ({duration/60:.1f} min)")
        
        # Estad√≠sticas avanzadas
        if self.metrics.get('game_lengths'):
            lengths = self.metrics['game_lengths']
            print(f"\\nüìè ESTAD√çSTICAS DE DURACI√ìN:")
            print(f"   Min: {min(lengths)} movimientos")
            print(f"   Max: {max(lengths)} movimientos")
            print(f"   Mediana: {np.median(lengths):.1f} movimientos")
            print(f"   Desv. est√°ndar: {np.std(lengths):.1f}")
        
        if self.metrics.get('rewards_per_game'):
            rewards = self.metrics['rewards_per_game']
            print(f"\\nüíé ESTAD√çSTICAS DE RECOMPENSAS:")
            print(f"   Promedio: {np.mean(rewards):.2f}")
            print(f"   Min: {min(rewards):.2f}")
            print(f"   Max: {max(rewards):.2f}")
            print(f"   Desv. est√°ndar: {np.std(rewards):.2f}")
    
    def plot_training_progress(self):
        """Genera gr√°ficos del progreso de entrenamiento"""
        if not self.metrics:
            print("‚ùå No hay m√©tricas disponibles para graficar")
            return
        
        # Crear directorio de gr√°ficos
        os.makedirs('plots', exist_ok=True)
        
        # Configurar subplots
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('üìä An√°lisis de Entrenamiento Q-Learning Connect 4', fontsize=16, fontweight='bold')
        
        # 1. Evoluci√≥n de Epsilon (Exploraci√≥n)
        if self.metrics.get('epsilon_history'):
            epsilon_history = self.metrics['epsilon_history']
            axes[0, 0].plot(epsilon_history, color='blue', linewidth=2)
            axes[0, 0].set_title('üé≤ Evoluci√≥n de Epsilon (Exploraci√≥n)')
            axes[0, 0].set_xlabel('Episodios')
            axes[0, 0].set_ylabel('Epsilon')
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].set_ylim(0, 1.05)
        
        # 2. Distribuci√≥n de duraci√≥n de juegos
        if self.metrics.get('game_lengths'):
            game_lengths = self.metrics['game_lengths']
            axes[0, 1].hist(game_lengths, bins=30, alpha=0.7, color='green', edgecolor='black')
            axes[0, 1].set_title('üìè Distribuci√≥n de Duraci√≥n de Juegos')
            axes[0, 1].set_xlabel('N√∫mero de Movimientos')
            axes[0, 1].set_ylabel('Frecuencia')
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].axvline(np.mean(game_lengths), color='red', linestyle='--', 
                              label=f'Promedio: {np.mean(game_lengths):.1f}')
            axes[0, 1].legend()
        
        # 3. Distribuci√≥n de recompensas
        if self.metrics.get('rewards_per_game'):
            rewards = self.metrics['rewards_per_game']
            axes[1, 0].hist(rewards, bins=30, alpha=0.7, color='orange', edgecolor='black')
            axes[1, 0].set_title('üíé Distribuci√≥n de Recompensas por Juego')
            axes[1, 0].set_xlabel('Recompensa Total')
            axes[1, 0].set_ylabel('Frecuencia')
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].axvline(np.mean(rewards), color='red', linestyle='--',
                              label=f'Promedio: {np.mean(rewards):.2f}')
            axes[1, 0].legend()
        
        # 4. Resumen de resultados
        wins = self.metrics.get('wins', 0)
        losses = self.metrics.get('losses', 0)
        draws = self.metrics.get('draws', 0)
        
        if wins + losses + draws > 0:
            labels = ['Victorias', 'Derrotas', 'Empates']
            sizes = [wins, losses, draws]
            colors = ['#2ecc71', '#e74c3c', '#f39c12']
            
            # Filtrar valores que son 0
            filtered_data = [(label, size, color) for label, size, color in zip(labels, sizes, colors) if size > 0]
            if filtered_data:
                labels, sizes, colors = zip(*filtered_data)
                
                wedges, texts, autotexts = axes[1, 1].pie(sizes, labels=labels, autopct='%1.1f%%', 
                                                         colors=colors, startangle=90)
                axes[1, 1].set_title('üèÜ Distribuci√≥n de Resultados')
                
                # Mejorar apariencia del texto
                for autotext in autotexts:
                    autotext.set_color('white')
                    autotext.set_fontweight('bold')
        
        plt.tight_layout()
        plt.savefig('plots/training_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("üìÅ Gr√°fico guardado en: plots/training_analysis.png")
    
    def plot_learning_curve(self, checkpoint_file='metrics/checkpoint_data.json'):
        """Grafica la curva de aprendizaje usando datos de checkpoints"""
        try:
            with open(checkpoint_file, 'r') as f:
                checkpoint_data = json.load(f)
        except FileNotFoundError:
            print(f"‚ùå No se encontr√≥ {checkpoint_file}")
            return
        
        if not checkpoint_data:
            print("‚ùå No hay datos de checkpoints disponibles")
            return
        
        episodes = [cp['episode'] for cp in checkpoint_data]
        win_rates = [cp['win_rate'] for cp in checkpoint_data]
        epsilons = [cp['epsilon'] for cp in checkpoint_data]
        q_sizes = [cp['q_table_size'] for cp in checkpoint_data]
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        fig.suptitle('üìà Curva de Aprendizaje Q-Learning', fontsize=16, fontweight='bold')
        
        # 1. Tasa de victoria a lo largo del tiempo
        axes[0].plot(episodes, [wr * 100 for wr in win_rates], marker='o', linewidth=2, markersize=4)
        axes[0].set_title('üèÜ Evoluci√≥n Tasa de Victoria')
        axes[0].set_xlabel('Episodios')
        axes[0].set_ylabel('Tasa de Victoria (%)')
        axes[0].grid(True, alpha=0.3)
        axes[0].set_ylim(0, 100)
        
        # 2. Epsilon vs Episodios
        axes[1].plot(episodes, epsilons, marker='s', linewidth=2, markersize=4, color='orange')
        axes[1].set_title('üé≤ Decay de Exploraci√≥n (Epsilon)')
        axes[1].set_xlabel('Episodios')
        axes[1].set_ylabel('Epsilon')
        axes[1].grid(True, alpha=0.3)
        axes[1].set_ylim(0, 1)
        
        # 3. Crecimiento de la tabla Q
        axes[2].plot(episodes, q_sizes, marker='^', linewidth=2, markersize=4, color='green')
        axes[2].set_title('üß† Crecimiento Tabla Q')
        axes[2].set_xlabel('Episodios')
        axes[2].set_ylabel('Estados en Tabla Q')
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('plots/learning_curve.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("üìÅ Curva de aprendizaje guardada en: plots/learning_curve.png")
    
    def generate_report(self):
        """Genera un reporte completo en texto"""
        if not self.metrics:
            print("‚ùå No hay m√©tricas disponibles para el reporte")
            return
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report = f"""
ü§ñ REPORTE DE ENTRENAMIENTO Q-LEARNING CONNECT 4
===============================================
Generado el: {timestamp}

CONFIGURACI√ìN DEL AGENTE:
- Tasa de aprendizaje (Œ±): {self.metrics.get('learning_rate', 'N/A')}
- Factor de descuento (Œ≥): {self.metrics.get('discount_factor', 'N/A')}
- Epsilon inicial: 1.0
- Epsilon final: {self.metrics.get('current_epsilon', 'N/A'):.3f}
- Epsilon m√≠nimo: 0.1

RESULTADOS DEL ENTRENAMIENTO:
- Juegos totales jugados: {self.metrics.get('games_played', 0)}
- Victorias: {self.metrics.get('wins', 0)} ({self.metrics.get('win_rate', 0):.1%})
- Derrotas: {self.metrics.get('losses', 0)}
- Empates: {self.metrics.get('draws', 0)}
- Duraci√≥n promedio: {self.metrics.get('avg_game_length', 0):.1f} movimientos

APRENDIZAJE:
- Estados explorados: {self.metrics.get('q_table_size', 0)}
- Recompensa promedio por episodio: {self.metrics.get('avg_reward_per_episode', 0):.2f}
"""
        
        if self.metrics.get('training_duration'):
            duration = self.metrics['training_duration']
            report += f"- Tiempo total de entrenamiento: {duration:.1f}s ({duration/60:.1f} minutos)\\n"
        
        # Estad√≠sticas adicionales
        if self.metrics.get('game_lengths'):
            lengths = self.metrics['game_lengths']
            report += f"""
AN√ÅLISIS ESTAD√çSTICO:
- Duraci√≥n m√≠nima: {min(lengths)} movimientos
- Duraci√≥n m√°xima: {max(lengths)} movimientos
- Mediana de duraci√≥n: {np.median(lengths):.1f} movimientos
- Desviaci√≥n est√°ndar: {np.std(lengths):.1f}
"""
        
        if self.metrics.get('rewards_per_game'):
            rewards = self.metrics['rewards_per_game']
            report += f"""
AN√ÅLISIS DE RECOMPENSAS:
- Recompensa m√≠nima: {min(rewards):.2f}
- Recompensa m√°xima: {max(rewards):.2f}
- Desviaci√≥n est√°ndar: {np.std(rewards):.2f}
"""
        
        report += f"""
CONCLUSIONES:
- El agente alcanz√≥ una tasa de victoria del {self.metrics.get('win_rate', 0):.1%}
- Se exploraron {self.metrics.get('q_table_size', 0)} estados √∫nicos del juego
- La exploraci√≥n se redujo gradualmente de 100% a {self.metrics.get('current_epsilon', 0)*100:.1f}%

===============================================
"""
        
        # Guardar reporte
        os.makedirs('reports', exist_ok=True)
        report_file = f"reports/training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(report)
        print(f"üìÅ Reporte guardado en: {report_file}")

def main():
    """Funci√≥n principal"""
    print("üìä An√°lisis de M√©tricas de Entrenamiento Q-Learning")
    print("=" * 50)
    
    # Crear analizador
    analyzer = MetricsAnalyzer()
    
    if analyzer.metrics:
        # Imprimir resumen
        analyzer.print_summary()
        
        # Generar gr√°ficos
        print("\\nüé® Generando visualizaciones...")
        analyzer.plot_training_progress()
        analyzer.plot_learning_curve()
        
        # Generar reporte completo
        print("\\nüìù Generando reporte completo...")
        analyzer.generate_report()
        
        print("\\n‚úÖ An√°lisis completado!")
        print("üìÅ Revisa las carpetas 'plots' y 'reports' para los resultados")
    else:
        print("‚ùå No se pudieron cargar las m√©tricas. ¬øYa entrenaste el agente?")
        print("üí° Ejecuta primero: python train_agent.py")

if __name__ == "__main__":
    main()